# -*- coding: utf-8 -*-
"""ex 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GTgPYNtadpDjtDcO_GsfNNKiEBpqr5G_
"""

# ==============================
# ðŸ“˜ Logistic Regression in Python
# ==============================

import pandas as pd
import numpy as np
from numpy import log, dot, exp, shape
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

# ------------------------------
# ðŸ“‚ Load Dataset
# ------------------------------
data = pd.read_csv('../input/suvcars/suv_data.csv')
print(data.head())

# Extract features and labels
x = data.iloc[:, [2, 3]].values
y = data.iloc[:, 4].values

# ------------------------------
# ðŸ”¹ In-built Logistic Regression
# ------------------------------
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=0)

# Standardize the features
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

print("First 10 Standardized Training Samples:\n", x_train[0:10, :])

# Train model
classifier = LogisticRegression(random_state=0)
classifier.fit(x_train, y_train)

# Predict
y_pred = classifier.predict(x_test)
print("Predicted Values:\n", y_pred)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:\n", cm)

# Accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))

# ------------------------------
# ðŸ”¹ User-defined Logistic Regression
# ------------------------------

# Split again for clarity
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=0)

# Manual standardization
def standardize(X_tr):
    for i in range(shape(X_tr)[1]):
        X_tr[:, i] = (X_tr[:, i] - np.mean(X_tr[:, i])) / np.std(X_tr[:, i])
    return X_tr

x_train = standardize(x_train)
x_test = standardize(x_test)

# Custom F1 Score function
def F1_score(y, y_hat):
    tp, tn, fp, fn = 0, 0, 0, 0
    for i in range(len(y)):
        if y[i] == 1 and y_hat[i] == 1:
            tp += 1
        elif y[i] == 1 and y_hat[i] == 0:
            fn += 1
        elif y[i] == 0 and y_hat[i] == 1:
            fp += 1
        elif y[i] == 0 and y_hat[i] == 0:
            tn += 1
    precision = tp / (tp + fp)
    recall = tp / (tp + fn)
    f1_score = 2 * precision * recall / (precision + recall)
    return f1_score

# ------------------------------
# Custom Logistic Regression Class
# ------------------------------
class LogisticRegressionCustom:
    def sigmoid(self, z):
        return 1 / (1 + exp(-z))

    def initialize(self, X):
        weights = np.zeros((shape(X)[1] + 1, 1))
        X = np.c_[np.ones((shape(X)[0], 1)), X]
        return weights, X

    def fit(self, X, y, alpha=0.001, iterations=400):
        weights, X = self.initialize(X)

        def cost(theta):
            z = dot(X, theta)
            cost0 = y.T.dot(log(self.sigmoid(z)))
            cost1 = (1 - y).T.dot(log(1 - self.sigmoid(z)))
            cost = -((cost1 + cost0)) / len(y)
            return cost

        cost_list = np.zeros(iterations,)
        for i in range(iterations):
            weights = weights - alpha * dot(X.T, self.sigmoid(dot(X, weights)) - np.reshape(y, (len(y), 1)))
            cost_list[i] = cost(weights)

        self.weights = weights
        return cost_list

    def predict(self, X):
        z = dot(self.initialize(X)[1], self.weights)
        preds = []
        for i in self.sigmoid(z):
            if i > 0.5:
                preds.append(1)
            else:
                preds.append(0)
        return np.array(preds)

# ------------------------------
# Train & Evaluate Custom Model
# ------------------------------
obj1 = LogisticRegressionCustom()
obj1.fit(x_train, y_train)

y_pred_test = obj1.predict(x_test)
y_pred_train = obj1.predict(x_train)

f1_score_train = F1_score(y_train, y_pred_train)
f1_score_test = F1_score(y_test, y_pred_test)

print("\nCustom Logistic Regression F1 Scores:")
print("Training F1 Score:", f1_score_train)
print("Testing F1 Score:", f1_score_test)