# -*- coding: utf-8 -*-
"""ex_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10dkvYJXpPPZEIFl_lsEAzdBrrY8yO4r_
"""

import numpy as np

# Input and output data
input_value = np.array([[0,0], [0,1], [1,1], [1,0]])
output = np.array([[0], [0], [1], [0]])

# Initialize weights and bias
weights = np.array([[0.1], [0.3]])
bias = 0.2

# Sigmoid function
def sigmoid_func(x):
    return 1 / (1 + np.exp(-x))

# Derivative of sigmoid
def der_sigmoid(x):
    return sigmoid_func(x) * (1 - sigmoid_func(x))

# Training
lr = 0.05  # learning rate

for epoch in range(15000):

    # Forward pass
    weighted_sum = np.dot(input_value, weights) + bias
    predicted = sigmoid_func(weighted_sum)

    # Error
    error = predicted - output

    # Derivative for gradient descent
    derivative = error * der_sigmoid(weighted_sum)

    # Update weights & bias
    weights -= lr * np.dot(input_value.T, derivative)
    bias -= lr * np.sum(derivative)

# Final weights and bias
print("Weights:\n", weights)
print("Bias:", bias)

# Testing
def predict(x):
    return sigmoid_func(np.dot(x, weights) + bias)

print("\nPredictions:")
print("1,0  →", predict(np.array([1,0])))
print("1,1  →", predict(np.array([1,1])))
print("0,0  →", predict(np.array([0,0])))
print("0,1  →", predict(np.array([0,1])))